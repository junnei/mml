---
layout: default
title: 모델 선택
lang: kr
lang-ref: model-selection
parent: When Models Meet Data
permalink: /kr/when-models-meet-data/8-6
nav_order: 6
writer: jo0n-lab
---

# 모델 선택
{: .no_toc }


Section 6 : Model Selection
{: .fs-5 .fw-300 }

8.6절에서는 데이터셋을 활용하여 효과적인 모델을 선택하는 방법론에 대해 알아본다.

{% include writer.html writer=page.writer lang=page.lang %}

---

- 목차
    {: .text-gamma }

    1. TOC
    {:toc}

---

## Nested Cross-Validation

8.2절에서 K Fold Cross-Validation 수행시 연산량이 K배 증가함을 단점으로 언급하고, 이에 대한 보완책으로 Nested Cross-Validation 을 언급한 바 있다.

Nested Cross-Validation 은 데이터셋을 $K$ fold로 나눈 뒤, $K$ fold 안에서 또 한번 $K$ fold로 나눈다. 

<div style="text-align : center;">
    <img src="{{ site.figure | absolute_url }}8.6.1.png" width="700px"/>
    <figcaption>$\textrm{Fig.1 $K=5$ 일 때 Nested Cross-Validation}$</figcaption>
</div>

최초 $K$ fold 에 $[M_1,M_2,\cdots,M_{K}]$ 을 대응시켜 각각의 모델에 대해 K Fold Cross-Validation 을 진행한다.
각각에 모델을 학습시키고 평가하는 작업은 독립적으로(for loop 없이) 진행이 가능하므로 연산량이 K배 로 증가하지 않는다.

Nested Cross-Validation 이후에는 $[M_1,M_2,\cdots,M_{K}]$ 에서 적합한 모델 하나를 결정해야한다.

$$p(X|\theta)=\frac{p(\theta|X)p(X)}{p(\theta)}$$

을 이용한 parameter $\theta_K(M_K)$가 주어졌을 때의 $X(\mathcal{D})$의 분포는 모델 선택의 합리적인 기준이 된다.

<div style="text-align : center;">
    <img src="{{ site.figure | absolute_url }}8.6.2.png" width="700px"/>
    <figcaption>$\textrm{Fig.2 $M_1,M_2$가 주어졌을 때 $\mathcal{D}$의 분포}$</figcaption>
</div>

위와 같은 경우, 평균이 가운데로 정렬이 잘 되어있으니(unbiased), 분포의 길이(신뢰구간)(variance)가 모델을 결정할 것이다.
즉, 길이가 더 짧은 $M_1$을 선택하는 것이 합리적이다.

그러나, 위의 경우는 주어진 데이터셋에 대한 variance를 통해 합리적인 모델을 골랐을 뿐, 새로운 데이터 즉, 서비스 시 실제로 만나게 될 데이터에 대한 학습 또는 평가가 이루어지지 않았다(이루어질 수 없다). 즉, 주어진 데이터에는 과적합(overfit)하게 되는 문제가 야기될 수 있다.


## Basyesian Model Selection

과적합(overfitting)을 생각하면 너무 깊은(deep) 모델도 적합하지 않다. Occam's Razor 이론에 따르면, 간단한 모델이 과적합을 방지하고 새로운 데이터에 대해 더 높은 성능을 보인다는 것이다. 

해당 이론을 수학적으로 구체화시키기 위해 8.4절의 베이지안 추론을 끌어올 수 있다.

---

$$
\begin{equation}
M=[M_1,M_2,\cdots,M_K]\\
M_k\sim p(M)\\
\theta_k\sim p(\theta|M_k)\\
\mathcal{D}\sim p(\mathcal{D}|\theta_k)\\
p(\mathcal{D}|M_k)=\int p(\mathcal{D}|\theta_k)p(\theta_k|M_k)d\theta_k\\
\therefore p(M_k|\mathcal{D}) \propto p(M_k)p(\mathcal{D}|M_k)\\
\therefore M^*=\textrm{arg}\underset{M_k}{\textrm{max}}\,p(M_k|\mathcal{D})\\
\text{주의!! } K\text{와 }k\text{를 구분하자.}
\end{equation}
$$


---
수학적의미를 한줄 한줄 분석해보면 다음과 같다.
> * 모델의 모집합 $M$ 은 $M_1,M_2,\cdots,M_k$으로 이루어져 있다.
> * 모델 $M_k$는 모집합 $M$의 분포를 따른다. 즉 $p(M_k)=\frac{1}{k}$
> * $\theta_k$는 $M_k$가 학습한 산물(artifact)이므로 $\theta_k$ 는 $M_k$에 의해 결정되는 분포를 따른다.
> * $\theta_k$에 따라 데이터셋 $\mathcal{D}$의 분포가 달라지므로 $\mathcal{D}$는 $\theta_k$에 의해 결정되는 분포를 따른다.
> * $p$($M_k$가 주어졌을 때 $\mathcal{D}$) = $p(M_k$ 주어졌을 때 $\theta_k)$ * $p(\theta_k$ 주어졌을 때 $\mathcal{D})$ \\
> 이므로 이를 적분한 결과가 된다.
> * 이 같은 비례관계는 자명(trivial)하다. 다만, 식에서 $\theta_k$가 등장하지 않음을 확인하자. 이것은 앞선 적분식에서 $\theta_k$를 차단한 결과이다.
> * 일련의 과정을 통해 수학적으로 타당한 "주어진 데이터에서 모델을 선택" 하는 방법을 유도했다.






---

{% include category.html category=page.parent id=6 %}
