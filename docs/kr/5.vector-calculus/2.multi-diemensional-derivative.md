---
layout: default
title: 다차원 미분
lang: kr
lang-ref: 5-2
parent: 벡터 미적분학
permalink: /kr/vector-calculus/5-2
nav_order: 2
writer: jo0n-lab, CSJasper
---

# 다차원 미분
{: .no_toc }


이번 절에서는 다차원으로 확장된 미분을 5.1 절에서 제시된 방법을 통해 알아본다.
{: .fs-5 .fw-300 }


{% include writer.html writer=page.writer lang=page.lang %}

---

- 목차
    {: .text-gamma }

    1. TOC
    {:toc}

---

## 차원의 확장(스칼라 $\rightarrow$ 벡터) 
5.1 절의 ```일차원```의 예시처럼, 상태를 하나의 차원으로 대표할 수 있는 값을 스칼라(scalar)라고 한다.\\
반면, 공간상의 3차원 위치를 표현하기 위해 $x,y,z$ 축이 필요하듯, 상태를 표현하기 위해 다양한 차원이 요구되는 것을 벡터(vector)라고 한다.

다음의 예시를 통해 스칼라와 벡터의 관계를 알아보자.

---

$$
X \in \mathbb{R}^n,\;\; Y=X^TX\\
$$

$$
X=\left[\begin{matrix} x_1 & x_2 & \cdots &x_n\end{matrix}\right]^T=x_1 \hat{x}_1+x_2 \hat{x}_2+ \cdots +x_n \hat{x}_n
$$

$$
Y=\left[\begin{matrix}x_{1} & x_{2} & \cdots & x_{n}\end{matrix}\right] \left[\begin{matrix} x_{1}\\ x_{2}\\ \vdots \\ x_{n}\end{matrix}\right]=x_1^2+x_2^2+\cdots+x_n^2
$$

---

$X$ 가 $n$ 차원 벡터($X \in \mathbb{R}^n$)임에도 불구하고, $Y$ 가 일차원 스칼라($Y \in \mathbb{R}$)로 도출되는 것이 흥미롭다.

        🔥 이처럼 다변수 사이의 연산 후에는 기존의 차원에서 변형이 생길 수 있다(특히 곱연산).

즉, 위의 경우에는 벡터와 벡터 사이의 곱연산 후에 결과값이 스칼라로 차원이 변환된 경우이다.

## 벡터의 미분(gradient)

벡터 미분은 gradient($grad(v)=\nabla v$) 라는 특수한 연산자에 의해 실현된다.\\
이는 5.1 절에서 나눗셈을 통한 미분의 정의를 벡터에 적용할 수 없으므로 새로운 연산자를 정의한 것이다.(벡터의 나눗셈이 불가능한 이유는 후의 절에서 다룰 것이다.)
gradient 연산의 결과는 벡터를 이루는 차원 변수들에 대한 편미분을 열방향(col stream)으로 펼친 벡터이다. gradient 연산의 대상은 스칼라와 벡터가 모두 가능하다.

---

$$
\begin{align}
\frac{dY}{dX}
&=grad(Y)=\nabla Y\\
&=\frac{\partial(x_1^2+\cdots+x_n^2)}{\partial x_1}\hat{x}_1+\frac{\partial(x_1^2+\cdots+x_n^2)}{\partial x_2}\hat{x}_2+\cdots+\frac{\partial (x_1^2+\cdots+x_n^2)}{\partial x_n}\hat{x}_n\\
&=\sum_{i=1}^{n} \frac{\partial Y}{\partial x_i}\cdot \hat x_i
\end{align}
$$

$$
\begin{align}
\frac{\partial Y}{\partial x_i}&=\frac{\partial (x_1^2+\cdots+x_i^2+\cdots+x_n^2)}{\partial x_i}\\
&=\lim \limits_{h \to 0} \frac{ (x_1^2+\cdots+(x_i+h)^2+\cdots+x_n^2)-(x_1^2+\cdots+x_i^2+\cdots+x_n^2)}{h}\\
&=\lim \limits_{h \to 0} \frac{(x_i+h)^2-x_i^2}{h}=2x_i
\end{align}
$$

---

---

$$
\begin{align}
\frac{dY}{dX}
&=\sum_{i=1}^{n} \frac{\partial Y}{\partial x_i}\cdot \hat x_i=\sum_{i=1}^{n} 2x_i\cdot \hat x_i\\
&=2x_1\cdot\hat x_1+2x_2\cdot\hat x_2+\cdots+2x_n\cdot\hat x_n\\
&=2X^T=\left[\begin{matrix}2x_{1} & 2x_{2} & \cdots & 2x_{n}\end{matrix}\right]
\end{align}
$$

---


여기서 확인해야할 것은,

        🔥 gradient 의 결과가 행벡터, 즉 차원변수(x1,x2,...,xn) 에 대한 편미분을 열방향으로 펼친 행벡터

라는 것이다.

또한, 앞선 곱연산의 차원 변화와 비슷하게,

        🔥 차원변수에 의한 열방향 확장의 결과로 열방향(차원의 양끝단 .shape[-1] or .shape[0])으로 차원확장(차원변화)

이 일어난다는 것이다.


## 곱미분 법칙(product rule)
gradient 연산에서도 곱미분 법칙이 적용된다. 

---

$$
\begin{align}
\frac{dY}{dX}
&=\frac{d}{dX}X^TX\\
&=\frac{dX^T}{dX}X+X^T\frac{dX}{dX}\\
&=grad(X^T)X+X^T grad(X)
\end{align}
$$

---
---

$$
\begin{equation}
\tag{$1^{st}$ term}
\frac{dX^T}{dX}=\left[\begin{matrix} \frac{dX^T}{dx_1} & \frac{dX^T}{dx_2} & \frac{dX^T}{dx_3} & \cdots & \frac{dX^T}{dx_n}\end{matrix}\right]\\ 
\end{equation}
$$

$$
\begin{equation}
\frac{dx_1}{dX}=e_1=\left[\begin{matrix}1 & 0 & 0 & \cdots & 0 \end{matrix}\right]\\
\frac{dx_2}{dX}=e_2=\left[\begin{matrix}0 & 1 & 0 & \cdots & 0 \end{matrix}\right]\\
\frac{dx_3}{dX}=e_3=\left[\begin{matrix}0 & 0 & 1 & \cdots & 0 \end{matrix}\right]\\
\;\;\;\;\;\;\;\;\;\;\vdots\\
\frac{dx_n}{dX}=e_n=\left[\begin{matrix}0 & 0 & 0 & \cdots & 1 \end{matrix}\right]\\
\left(e_i.\mathtt{shape=(1,n)}\right)\\
\end{equation}
$$



$$
\begin{equation}
\frac{dX^T}{dX}
=\left[\begin{matrix}e_1 & e_2 & e_3 & \cdots & e_n \end{matrix}\right]\\
=\left[\begin{matrix}[1\;0\;0\ldots 0] & [0\;1\;0 \ldots 0] & [0\;0\;1 \ldots 0] & \cdots & [0\;0\;0 \ldots 1] \end{matrix}\right]\\
\left(\frac{dX^T}{dX}.\mathtt{shape=(n,1,n)}\right)
\end{equation}
$$

$$
\begin{align}
\therefore \frac{dX^T}{dX}
&=\left[\begin{matrix}e_1x_1 & e_2x_2 & e_3x_3 & \cdots & e_nx_n \end{matrix}\right]\\
&=\left[\begin{matrix}x_1 & x_2 & x_3 & \cdots & x_n \end{matrix}\right]=X^T
\end{align}
$$

---

---

$$
\begin{align}
\tag{$2^{nd}$ term}
\frac{dX}{dX}
&=\left[\begin{matrix}\frac{\partial X}{\partial x_1} & \frac{\partial X}{\partial x_2} & \frac{\partial X}{\partial x_3} & \cdots &\frac{\partial X}{\partial x_n}\end{matrix}\right]\\
&=\left[\begin{matrix} e_1^T & e_2^T & e_3^T & \cdots & e_n^T \end{matrix}\right]\\
&=\left[ {\begin{array}{cccc}
1 & 0 & \cdots & 0\\
0 & 1 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1\\
\end{array} } \right]=E^{(n,n)}
\end{align}
$$


$$
\begin{equation}
\therefore \frac{dX}{dX}X^T=\left[\begin{matrix}x_{1} & x_{2} & \cdots & x_{n}\end{matrix}\right]=X^T
\end{equation}
$$

---

---

$$
\begin{equation}
\therefore \frac{dY}{dX}=\frac{d}{dX}X^TX=\frac{dX^T}{dX}X+X^T\frac{dX}{dX}=X^T+X^T=2X^T
\end{equation}
$$

---

$1^{st},2^{nd}$ 에서 벡터가 열방향으로 확장되는 것을 확인할 수 있다.
>$\frac{dX^T}{dX}$ 경우,$\left(\frac{dX^T}{dX}\,:\,(1,n) \rightarrow (n,1,n) \right)$

>$\frac{dX}{dX}$ 경우, $\left(\frac{dX}{dX}\,:\,(n,1) \rightarrow (n,n) \right)$

## 더 알아보기

다차원의 벡터에서 상태를 대표하는 차원을 선택하는 것은 중요한 작업이 될 수 있다.\\
데이터 전처리의 경우, 차원을 어떻게 설정하느냐에 따라 모델의 학습에서 큰 성능의 차이를 보이기도 한다.\\
또한, 차원을 직교하게(orthogonal) 선택하여 나중의 작업에서 통제하기 용이하다. (coursera dls : C3W1L02)

---
 
 
 



{% include category.html category=page.parent id=2 %}





<!-- 이와 같은 미분이 가능한 이유는 $x,y$ 의 관계가 독립적(```합성함수``` 관계가 아닌)이기 때문이다.

        🔥 이러한 관계를 수학적으로 'x와 y는 직교(orthogonal)한다' 라고 한다.  
        
        \begin{equation}
        (x,y)\;is\;orthogonal\;:\;x \perp y
        \end{equation}-->
