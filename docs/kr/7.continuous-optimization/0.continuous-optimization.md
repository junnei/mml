---
layout: default
title: 연속 최적화
lang: kr
lang-ref: continuous-optimization
has_children: true
permalink: /kr/continuous-optimization
nav_order: 7
writer: sulog
---

# 연속 최적화
{: .no_toc }


Introduction : Continuous Optimization
{: .fs-5 .fw-300 }

{% include writer.html writer=page.writer lang=page.lang %}

---

## 연속 최적화

**연속 최적화**는 머신러닝에서 목적함수에 의해 결정되는 최적 파라미터를 찾기 위한 수치해석적 방법이다. 여기서 수치해석적 방법이란 연속수학 문제를 해결하기 위해 추측으로부터 근사치를 구하는 방법을 뜻한다. **정확한 해**를 구하기 힘든 경우, 현대 컴퓨터의 성능을 활용해 알고리즘을 무한히 반복하여 **근사 해**를 구해나가는 방법으로 생각할 수 있다. 

전통적으로 머신러닝의 목적 함수는 **최소화** 되도록 설계된다. 직관적으로 최적값을 찾기 위해서는 목적함수의 골짜기를 찾는 것과 같고, 여기서 공간의 **기울기(gradient)**는 골짜기의 오르막 방향을 가리킨다. 즉, 가장 깊은 곳을 찾기위해서는 내리막인 기울기의 반대 방향으로 가야한다. 



7.1 에서는 연속최적화의 몇 가지 디자인을 배우고, 7.2 에서는 제약이란 개념을 추가해 제약 최적화에 대해서 다룰 예정이다. 7.3 에서는 전역 최적해에 다다를 수 있는 볼록 최적 문제를 소개하겠다. 

### **그림1** Chapter7 연속최적화 마인드맵
{: .no_toc .text-delta }
<img src="{{ site.figure | absolute_url }}7.0.0.png" width="700px"/>
 


