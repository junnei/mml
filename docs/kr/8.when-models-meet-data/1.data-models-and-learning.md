---
layout: default
title: 데이터, 모델, 그리고 학습
lang: kr
lang-ref: data-models-and-learning
parent: When Models Meet Data
permalink: /kr/when-models-meet-data/8-1
nav_order: 1
writer: dnwjddl
---

# 데이터, 모델, 그리고 학습
{: .no_toc }


Chapter 1 : Data, Models, and Learning
{: .fs-5 .fw-300 }


{% include writer.html writer=page.writer lang=page.lang %}

---

- 목차
    {: .text-gamma }

    1. TOC
    {:toc}

---

# 데이터, 모델, 그리고 학습

### 8.1.1 Data vs Vectors

각 행: Instance, example
각 열: 특정한 Feature

* 좋은 Feature을 찾아내는 다양한 **전처리** 과정을 거쳐야 함
ex. 범주형 Feature -> 수치형 Feature로 변환
  - Gender Feature: 남, 여 -> 1, -1
  - Degree: 학사, 석사, 박사 -> 1, 2, 3

전처리 거친 데이터셋 $x_n$  
- N: 개체의 수
- $x_n$: Example 혹은 Datapoint
- $x_n$은 D-dimensional Vector로 표현  

Label $y_n$이 존재 -> **Supervised Learning**이라 함  

좋은 representation을 위해서는 두가지 방법 존재
1. finding low-dimensional approximations of the original feature vector
  - Chapter 10. 중요한 component만 뽑아냄
2. using non-linear high dimensional combinations of the original feature vector
  - high dimensional을 표현하기 위해 feature mapping $\phi(x_n)$을 이용해서 표현
  - 이 표현방식은 높은 차원의 데이터가 낮은 차원에서 non-linear 한 조합으로 다시표현 가능
  - 이러한 Feature map은 Chapter 9.2 kernel funciton을 이용해 좀 더 쉽게 수행

---

데이터를 적절한 벡터로 표현 완료!  
Predictor로 불리는 적절한 예측함수 구축하는 것
- 함수로서의 predictor
- 확률적 모델의 predictor

---


### 8.1.2 Models as Functions
**함수로서의 Predictor**

$$f:\mathbb{R}^D \rightarrow \mathbb{R}$$

(input: Example Vector, output: 실수 하나)

$$f(x) = \theta^Tx + \theta_0$$

(선형함수)


### 8.1.3 Models as probability Distributions
**확률적 모델의 Predictor**

Data에는 노이즈 자주 발생  
머신러닝을 학습할때는 이러한 노이즈 속에서도 특별한 signal을 발견하는 것이 목표  
그러기 위해서는 노이즈를 수치화 할 수 있어야 함  

$\therefore$ 확률이론을 활용해 Predictor Function 표현  


### 8.1.4 Learinng is Finding Parameters
Data를 잘 표현하는 적절한 Parameter를 찾아야 함
- 머신러닝 알고리즘 수행하는 대표적인 세가지 단계
1. Prediction or inference(예측, 추론)
   - 학습이 완료된 Prediction를 활용해 새로운 Test Data를 예측하는 단계
   - Parameter와 모델 선택은 이미 확정된 상태에서 Predictor가 새로운 Input data point에 적용이 되는 것
2. Training or parameter estimation (훈련, 파라미터 평가)
   - Training data로 학습된 예측 모델을 조정하는 단계
   - 주어진 Training data에 더 잘 맞도록 Predictor을 조정해야 함
3. Hyperparameter tuning or model selection (하이퍼파라미터 조정, 모델 선택)
   - **Non probabilistic 모델**: Empirical risk minimization이라는 원칙에 따라야 함
   - **Statistical 모델**: Maximum likelihood 으로 최적의 parameter 검출


Training set과 Test set에 대한 예측률은 서로 일정수준 이상에서 Trade-off 관계를 가짐
```정규화``` 혹은 ```Adding a prior```과정을 추가로 거쳐 모델을 단순화 => **```Abduction```**

**Abduction**이란, 최고의 설명을 위한 추론의 과정 (process of inference to the best explanation)


Model Selection을 하기 위해서는 **Nested Cross-Validation** 이라는 검증이 필요


---

{% include category.html category=page.parent id=1 %}
