---
layout: default
title: 정사영에 따른 최대우도
lang: kr
lang-ref: Maximum-Likelihood-as-Orthogonal-Projection
parent: 선형 회귀
permalink: /kr/linear-regression/9-4
nav_order: 4
writer: Kim-Ju-won
---

# 정사영에 따른 최대우도
{: .no_toc }


Chapter 4 : Maximum Likelihood as Orthogonal Projection
{: .fs-5 .fw-300 }


{% include writer.html writer=page.writer lang=page.lang %}

---

- 목차
    {: .text-gamma }

    1. TOC
    {:toc}

---
## 최대 우도 함수(Maximum Likelihood Function)과 최대 사후 확률(MAP)의 기하학적 접근

최대우도 및 최대 사후 확률(MAP) 추정치를 도출하기 위해 많은 내용의 대수학을 다뤘다. 이제 최대우도 추정에 대한 기하학적 해석에 대해서 살펴보자.

### 일차원 데이터에 대한 기하학적인 접근 

다음과 같은 간단한 선형 회귀 모델(Linear Regression)이 있다고 가정하자.

$$
y = x\theta + \epsilon, \epsilon \sim \mathcal{N}(0,\sigma^2)
$$

위 식은 $f : f \rightarrow \mathbb{R}$이고, 원점을 지나는 직선이라고 가정한다. 이 때 매개변수 $\theta$는 선형 회귀 함수의 기울기를 의미한다. $\{(x_1, y_1), . . . , (x_N , y_N )\}$와 같이 훈련데이터가 주어졌을 때 기울기 매개변수의 최대 우도 함수는 다음과 같다. 단($X = [x_1,...,x_N]^T \in \mathbb{R}^N, y = [y_1,...,y_N]^T \in \mathbb{R}^N$).

$$
\theta_{ML} = (X^TX)^{-1}X^Ty= \frac{X^Ty}{X^TX} \in \mathbb{R}
$$

이 때, 이 훈련 데이터를 이용해서 아래와 같은 회귀값을 얻을 수 있다. 

$$
X\theta_{ML}= X\frac{X^Ty}{X^TX}=\frac{XX^T}{X^TX}y
$$

$y$와 $X\theta$ 사이의 최소 제곱 오차(mean squarred error)로 근사치를 얻을 수 있다. 

$y=x\theta$의 선형 회귀 함수는 직선의 방정식의 해를 찾는 문제와 같다고 할 수 있다. 그러므로 Chapter 2,3장에서 설명한 선형대수학(linear Algebra)와해석기하학(analytic Geometry)의 개념과 관련지어 생각할 수 있다. 위 세번째 식을 주의깊게 보면, 첫번째 식의 $\theta_{ML}$ X에 걸쳐 있는 1차원 부분 공간에 y를 효과적으로 정사영이 된것을 확인할 수 있다. Section 3.8, $\frac{XX^T}{X^TX}$를 정사영 행렬로, $\theta_{ML}$을 $X$와 $X\theta_{ML}$에 의해 확장된 $\mathbb{R}_N$의 1차원 부분 공간에 대한 투영 좌표로(부분 공간에 대한 y의 정사영)으로 식별될 수 있다.

따라서 최대 우도 해는 관측치 y에 "가장 가까운" X로 확장되는 부분공간에서 벡터를 찾아 기하학적으로 최적의 해법을 제공한다 여기서 "가장 가까운" 것은 함수 값 $y_n$에서 $x_n\theta$까지의 가장 작은 (제곱) 거리를 의미하며, 이는 정사영 과정을 통해 달성된다.

### 다차원 데이터에 대한 기하학적인 접근 

이를 다차원의 경우로 확장시켜서 생각해보면, 아래와 같은 일반적인 선형회귀 문제로 접근할 수 있다. 

$$
y= \phi^T(x)\theta + \epsilon, \epsilon \sim \mathcal{N}
$$

벡터 값의 특징(Vector-valued Feature)인 $\phi(x) \in \mathbb{R}^K$를 이용하여 최대 우도를 다음과 같이 해석할 수 있다.

$$
y \approx \Phi\theta_{ML}
$$

$$
\theta_{ML} = (\Phi^T\Phi)^{-1}\Phi^Ty
$$

위 값은 $K$ 차원의 부분공간을 사영 시켜 특징 행렬(feature matrix) $\Phi$의 열에 확장된 것과 같다. 만약 특징 함수(Feature function) $\phi_k$의 계산을 위해 활용한 $\Phi$가 직교정규(Orthonormal)하다면, $\Phi^T\Phi = I$인 특별한 경우가 되고, 아래의 정사영을 수행할 수 있다.

$$
\Phi(\Phi^T\Phi)^{-1}\Phi^Ty = \Phi\Phi^Ty = \sum_{k=1}^K (\phi_k\phi_k^T)y
$$

위 식과 같이 y에 사영된 값의 합으로 간단하게 표현할 수 있다. 

만약, 기저가 직교하지 않을 경우 Gram-Schmidt 프로세스를 사용하여 선형 독립 기저 함수 집합을 직교 기저로 변환할 수 있습니다. (Section 3.8.3 및 (Strang, 2003) 참고.)

---

{% include category.html category=page.parent id=4 %}